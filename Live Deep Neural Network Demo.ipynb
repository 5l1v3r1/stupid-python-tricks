{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, glob, re\n",
    "\n",
    "import cv2\n",
    "\n",
    "from deep_neural_network import face_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CAPTURE_FILENAME_PREFIX = 'capture'\n",
    "CAP_RE = re.compile('{0}([0-9]+).png'.format(CAPTURE_FILENAME_PREFIX))\n",
    "\n",
    "def _get_cap_start_index():\n",
    "    existing_cap_filenames = glob.glob('{0}*.png'.format(CAPTURE_FILENAME_PREFIX))\n",
    "    matches = [CAP_RE.match(fn) for fn in existing_cap_filenames]\n",
    "    indices = [int(m.group(1)) for m in matches if m is not None]\n",
    "    if len(indices) > 0:\n",
    "        return max(indices)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "CAP_INDEX = _get_cap_start_index() + 1\n",
    "last_cap_filename = ''\n",
    "print 'Capture file names start at {0}{1}.png'.format(CAPTURE_FILENAME_PREFIX, CAP_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def emotion_bar(image, index, probability, title):\n",
    "    h = 30\n",
    "    x = 250\n",
    "    y = (index+1) * h\n",
    "    w = int(probability * 100.0+0.5)\n",
    "    cv2.putText(image, '{0}: {1:.1f}%'.format(title, probability*100.0), (0, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0,255,255))\n",
    "    cv2.rectangle(image,(x,y-(h-2)),(x+w,y),(0,255,255),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "wrote_image_last_frame = False\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "        \n",
    "    anno_frame = frame.copy()\n",
    "    \n",
    "    Y_pred, face_boxes = face_classifier.detect_and_predict_face(frame)\n",
    "    \n",
    "    if Y_pred is not None:\n",
    "        for (x,y,w,h) in face_boxes:\n",
    "            cv2.rectangle(anno_frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            \n",
    "        for i, emotion in enumerate(face_classifier.EMOTIONS):\n",
    "            emotion_bar(anno_frame, i, Y_pred[i], emotion)\n",
    "        \n",
    "\n",
    "    if wrote_image_last_frame:\n",
    "        cv2.putText(anno_frame, 'Wrote {0}'.format(last_cap_filename), (0, 200),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255))\n",
    "        \n",
    "    cv2.imshow('Press ESC to exit ot SPACE to capture', anno_frame)\n",
    "    kp = cv2.waitKey(5) \n",
    "    if kp == ord(' '):\n",
    "        # Space\n",
    "        if not wrote_image_last_frame:\n",
    "            fn = '{0}{1}.png'.format(CAPTURE_FILENAME_PREFIX, CAP_INDEX)\n",
    "            cv2.imwrite(fn, frame)\n",
    "            last_cap_filename = fn\n",
    "            CAP_INDEX += 1\n",
    "        wrote_image_last_frame = True\n",
    "    elif kp == 27:\n",
    "        # ESC: exit\n",
    "        wrote_image_last_frame = False\n",
    "        break\n",
    "    else:\n",
    "        wrote_image_last_frame = False\n",
    "        \n",
    "\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
